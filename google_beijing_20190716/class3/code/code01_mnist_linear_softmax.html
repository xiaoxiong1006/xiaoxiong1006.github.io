
<!DOCTYPE HTML>
<html lang="" >
    <head>
        <meta charset="UTF-8">
        <meta content="text/html; charset=utf-8" http-equiv="Content-Type">
        <title>softmax回归代码清单 · GitBook</title>
        <meta http-equiv="X-UA-Compatible" content="IE=edge" />
        <meta name="description" content="">
        <meta name="generator" content="GitBook 3.2.3">
        
        
        
    
    <link rel="stylesheet" href="../gitbook/style.css">

    
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-highlight/website.css">
                
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-search/search.css">
                
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-fontsettings/website.css">
                
            
        

    

    
        
    
        
    
        
    
        
    
        
    
        
    

        
    
    
    <meta name="HandheldFriendly" content="true"/>
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black">
    <link rel="apple-touch-icon-precomposed" sizes="152x152" href="../gitbook/images/apple-touch-icon-precomposed-152.png">
    <link rel="shortcut icon" href="../gitbook/images/favicon.ico" type="image/x-icon">

    
    <link rel="next" href="code02_mnist_cnn.html" />
    
    
    <link rel="prev" href="../11_appendix_summary.html" />
    

    </head>
    <body>
        
<div class="book">
    <div class="book-summary">
        
            
<div id="book-search-input" role="search">
    <input type="text" placeholder="Type to search" />
</div>

            
                <nav role="navigation">
                


<ul class="summary">
    
    

    

    
        
        
    
        <li class="chapter " data-level="1.1" data-path="../">
            
                <a href="../">
            
                    
                    1.介绍
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2" data-path="../1_init.html">
            
                <a href="../1_init.html">
            
                    
                    2.准备工作
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3" data-path="../2_import_dataset.html">
            
                <a href="../2_import_dataset.html">
            
                    
                    3.导入数据
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.4" data-path="../3_explore_dataset.html">
            
                <a href="../3_explore_dataset.html">
            
                    
                    4.数据的探索
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.5" data-path="../4_preparing_dataset.html">
            
                <a href="../4_preparing_dataset.html">
            
                    
                    5.数据预处理
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6" data-path="../5_training.html">
            
                <a href="../5_training.html">
            
                    
                    6.训练模型
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.7" data-path="../6_evaluating.html">
            
                <a href="../6_evaluating.html">
            
                    
                    7.评估模型
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.8" data-path="../7_saving.html">
            
                <a href="../7_saving.html">
            
                    
                    8.保存模型
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.9" data-path="../8_loding_predicting.html">
            
                <a href="../8_loding_predicting.html">
            
                    
                    9.导入模型和使用模型
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.10" data-path="../10_adjustment.html">
            
                <a href="../10_adjustment.html">
            
                    
                    10.改进模型
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.11" data-path="../11_appendix_summary.html">
            
                <a href="../11_appendix_summary.html">
            
                    
                    附录
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter active" data-level="1.11.1" data-path="code01_mnist_linear_softmax.html">
            
                <a href="code01_mnist_linear_softmax.html">
            
                    
                    softmax回归代码清单
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.11.2" data-path="code02_mnist_cnn.html">
            
                <a href="code02_mnist_cnn.html">
            
                    
                    卷积神经网络代码清单
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    

    

    <li class="divider"></li>

    <li>
        <a href="https://www.gitbook.com" target="blank" class="gitbook-link">
            Published with GitBook
        </a>
    </li>
</ul>


                </nav>
            
        
    </div>

    <div class="book-body">
        
            <div class="body-inner">
                
                    

<div class="book-header" role="navigation">
    

    <!-- Title -->
    <h1>
        <i class="fa fa-circle-o-notch fa-spin"></i>
        <a href=".." >softmax回归代码清单</a>
    </h1>
</div>




                    <div class="page-wrapper" tabindex="-1" role="main">
                        <div class="page-inner">
                            
<div id="book-search-results">
    <div class="search-noresults">
    
                                <section class="normal markdown-section">
                                
                                <h1 id="&#x624B;&#x5199;&#x6570;&#x5B57;&#x7684;&#x8BC6;&#x522B;">&#x624B;&#x5199;&#x6570;&#x5B57;&#x7684;&#x8BC6;&#x522B;</h1>
<h2 id="1&#x63D0;&#x51FA;&#x95EE;&#x9898;">1.&#x63D0;&#x51FA;&#x95EE;&#x9898;</h2>
<p>&#x6839;&#x636E;&#x6574;&#x7406;&#x597D;&#x7684;mnist&#x6570;&#x636E;&#x96C6;&#xFF0C;&#x80FD;&#x591F;&#x8FDB;&#x884C;&#x5341;&#x79CD;&#x624B;&#x5199;&#x6570;&#x5B57;&#x7684;&#x8BC6;&#x522B;&#x3002;</p>
<pre><code class="lang-python"><span class="hljs-comment"># &#x5BFC;&#x5305;</span>
<span class="hljs-keyword">import</span> tensorflow <span class="hljs-keyword">as</span> tf
<span class="hljs-keyword">from</span> tensorflow.examples.tutorials.mnist <span class="hljs-keyword">import</span> input_data
<span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np
<span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt
</code></pre>
<h2 id="2&#x6570;&#x636E;&#x7684;&#x6536;&#x96C6;">2.&#x6570;&#x636E;&#x7684;&#x6536;&#x96C6;</h2>
<pre><code class="lang-python"><span class="hljs-comment"># &#x8BFB;&#x5165;&#x6570;&#x636E;&#x96C6;</span>
mnist = input_data.read_data_sets(<span class="hljs-string">&quot;datasets/&quot;</span>,one_hot=<span class="hljs-keyword">True</span>)
print(<span class="hljs-string">&quot;mnist&#x6570;&#x636E;&#x96C6;&#x4E0B;&#x8F7D;&#x5B8C;&#x6BD5;....&quot;</span>)
</code></pre>
<pre><code>WARNING:tensorflow:From &lt;ipython-input-3-e259b1bad7dd&gt;:2: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use alternatives such as official/mnist/dataset.py from tensorflow/models.
WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.
Instructions for updating:
Please write your own downloading logic.
WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:252: _internal_retry.&lt;locals&gt;.wrap.&lt;locals&gt;.wrapped_fn (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.
Instructions for updating:
Please use urllib or similar directly.



---------------------------------------------------------------------------

SSLError                                  Traceback (most recent call last)

/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/urllib/request.py in do_open(self, http_class, req, **http_conn_args)
   1317                 h.request(req.get_method(), req.selector, req.data, headers,
-&gt; 1318                           encode_chunked=req.has_header(&apos;Transfer-encoding&apos;))
   1319             except OSError as err: # timeout error


/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/http/client.py in request(self, method, url, body, headers, encode_chunked)
   1238         &quot;&quot;&quot;Send a complete request to the server.&quot;&quot;&quot;
-&gt; 1239         self._send_request(method, url, body, headers, encode_chunked)
   1240 


/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/http/client.py in _send_request(self, method, url, body, headers, encode_chunked)
   1284             body = _encode(body, &apos;body&apos;)
-&gt; 1285         self.endheaders(body, encode_chunked=encode_chunked)
   1286 


/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/http/client.py in endheaders(self, message_body, encode_chunked)
   1233             raise CannotSendHeader()
-&gt; 1234         self._send_output(message_body, encode_chunked=encode_chunked)
   1235 


/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/http/client.py in _send_output(self, message_body, encode_chunked)
   1025         del self._buffer[:]
-&gt; 1026         self.send(msg)
   1027 


/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/http/client.py in send(self, data)
    963             if self.auto_open:
--&gt; 964                 self.connect()
    965             else:


/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/http/client.py in connect(self)
   1399             self.sock = self._context.wrap_socket(self.sock,
-&gt; 1400                                                   server_hostname=server_hostname)
   1401             if not self._context.check_hostname and self._check_hostname:


/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/ssl.py in wrap_socket(self, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, session)
    406                          server_hostname=server_hostname,
--&gt; 407                          _context=self, _session=session)
    408 


/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/ssl.py in __init__(self, sock, keyfile, certfile, server_side, cert_reqs, ssl_version, ca_certs, do_handshake_on_connect, family, type, proto, fileno, suppress_ragged_eofs, npn_protocols, ciphers, server_hostname, _context, _session)
    813                         raise ValueError(&quot;do_handshake_on_connect should not be specified for non-blocking sockets&quot;)
--&gt; 814                     self.do_handshake()
    815 


/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/ssl.py in do_handshake(self, block)
   1067                 self.settimeout(None)
-&gt; 1068             self._sslobj.do_handshake()
   1069         finally:


/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/ssl.py in do_handshake(self)
    688         &quot;&quot;&quot;Start the SSL/TLS handshake.&quot;&quot;&quot;
--&gt; 689         self._sslobj.do_handshake()
    690         if self.context.check_hostname:


SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:777)


During handling of the above exception, another exception occurred:


URLError                                  Traceback (most recent call last)

&lt;ipython-input-3-e259b1bad7dd&gt; in &lt;module&gt;()
      1 # &#x8BFB;&#x5165;&#x6570;&#x636E;&#x96C6;
----&gt; 2 mnist = input_data.read_data_sets(&quot;datasets/&quot;,one_hot=True)
      3 print(&quot;mnist&#x6570;&#x636E;&#x96C6;&#x4E0B;&#x8F7D;&#x5B8C;&#x6BD5;....&quot;)


/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py in new_func(*args, **kwargs)
    304               &apos;in a future version&apos; if date is None else (&apos;after %s&apos; % date),
    305               instructions)
--&gt; 306       return func(*args, **kwargs)
    307     return tf_decorator.make_decorator(
    308         func, new_func, &apos;deprecated&apos;,


/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py in read_data_sets(train_dir, fake_data, one_hot, dtype, reshape, validation_size, seed, source_url)
    258 
    259   local_file = base.maybe_download(TRAIN_IMAGES, train_dir,
--&gt; 260                                    source_url + TRAIN_IMAGES)
    261   with gfile.Open(local_file, &apos;rb&apos;) as f:
    262     train_images = extract_images(f)


/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py in new_func(*args, **kwargs)
    304               &apos;in a future version&apos; if date is None else (&apos;after %s&apos; % date),
    305               instructions)
--&gt; 306       return func(*args, **kwargs)
    307     return tf_decorator.make_decorator(
    308         func, new_func, &apos;deprecated&apos;,


/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/base.py in maybe_download(filename, work_directory, source_url)
    250   filepath = os.path.join(work_directory, filename)
    251   if not gfile.Exists(filepath):
--&gt; 252     temp_file_name, _ = urlretrieve_with_retry(source_url)
    253     gfile.Copy(temp_file_name, filepath)
    254     with gfile.GFile(filepath) as f:


/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py in new_func(*args, **kwargs)
    304               &apos;in a future version&apos; if date is None else (&apos;after %s&apos; % date),
    305               instructions)
--&gt; 306       return func(*args, **kwargs)
    307     return tf_decorator.make_decorator(
    308         func, new_func, &apos;deprecated&apos;,


/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/base.py in wrapped_fn(*args, **kwargs)
    203       for delay in delays():
    204         try:
--&gt; 205           return fn(*args, **kwargs)
    206         except Exception as e:  # pylint: disable=broad-except
    207           if is_retriable is None:


/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/base.py in urlretrieve_with_retry(url, filename)
    231 @_internal_retry(initial_delay=1.0, max_delay=16.0, is_retriable=_is_retriable)
    232 def urlretrieve_with_retry(url, filename=None):
--&gt; 233   return urllib.request.urlretrieve(url, filename)
    234 
    235 


/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/urllib/request.py in urlretrieve(url, filename, reporthook, data)
    246     url_type, path = splittype(url)
    247 
--&gt; 248     with contextlib.closing(urlopen(url, data)) as fp:
    249         headers = fp.info()
    250 


/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/urllib/request.py in urlopen(url, data, timeout, cafile, capath, cadefault, context)
    221     else:
    222         opener = _opener
--&gt; 223     return opener.open(url, data, timeout)
    224 
    225 def install_opener(opener):


/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/urllib/request.py in open(self, fullurl, data, timeout)
    524             req = meth(req)
    525 
--&gt; 526         response = self._open(req, data)
    527 
    528         # post-process response


/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/urllib/request.py in _open(self, req, data)
    542         protocol = req.type
    543         result = self._call_chain(self.handle_open, protocol, protocol +
--&gt; 544                                   &apos;_open&apos;, req)
    545         if result:
    546             return result


/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/urllib/request.py in _call_chain(self, chain, kind, meth_name, *args)
    502         for handler in handlers:
    503             func = getattr(handler, meth_name)
--&gt; 504             result = func(*args)
    505             if result is not None:
    506                 return result


/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/urllib/request.py in https_open(self, req)
   1359         def https_open(self, req):
   1360             return self.do_open(http.client.HTTPSConnection, req,
-&gt; 1361                 context=self._context, check_hostname=self._check_hostname)
   1362 
   1363         https_request = AbstractHTTPHandler.do_request_


/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/urllib/request.py in do_open(self, http_class, req, **http_conn_args)
   1318                           encode_chunked=req.has_header(&apos;Transfer-encoding&apos;))
   1319             except OSError as err: # timeout error
-&gt; 1320                 raise URLError(err)
   1321             r = h.getresponse()
   1322         except:


URLError: &lt;urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:777)&gt;
</code></pre><h2 id="3&#x6570;&#x636E;&#x7684;&#x63A2;&#x7D22;">3.&#x6570;&#x636E;&#x7684;&#x63A2;&#x7D22;</h2>
<pre><code class="lang-python">idx = <span class="hljs-number">1046</span>
img = mnist.test.images[idx]
print(<span class="hljs-string">&quot;&#x6570;&#x636E;&#x7C7B;&#x578B;&#xFF1A;&quot;</span>, type(img))
print(<span class="hljs-string">&quot;&#x6570;&#x7EC4;&#x5143;&#x7D20;&#x7684;&#x6570;&#x636E;&#x7C7B;&#x578B;&quot;</span>,img.dtype)
print(<span class="hljs-string">&quot;&#x6570;&#x7EC4;&#x5143;&#x7D20;&#x7684;&#x603B;&#x6570;&quot;</span>,img.size)
print(<span class="hljs-string">&quot;&#x6570;&#x7EC4;&#x5143;&#x7D20;&#x7684;&#x5F62;&#x72B6;&quot;</span>,img.shape)
print(<span class="hljs-string">&quot;&#x6570;&#x7EC4;&#x5143;&#x7D20;&#x7684;&#x7EF4;&#x5EA6;&quot;</span>,img.ndim)
</code></pre>
<pre><code>&#x6570;&#x636E;&#x7C7B;&#x578B;&#xFF1A; &lt;class &apos;numpy.ndarray&apos;&gt;
&#x6570;&#x7EC4;&#x5143;&#x7D20;&#x7684;&#x6570;&#x636E;&#x7C7B;&#x578B; float32
&#x6570;&#x7EC4;&#x5143;&#x7D20;&#x7684;&#x603B;&#x6570; 784
&#x6570;&#x7EC4;&#x5143;&#x7D20;&#x7684;&#x5F62;&#x72B6; (784,)
&#x6570;&#x7EC4;&#x5143;&#x7D20;&#x7684;&#x7EF4;&#x5EA6; 1
</code></pre><pre><code class="lang-python">count = <span class="hljs-number">0</span>
<span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> img:
    print(<span class="hljs-string">&quot;%4d&quot;</span> %(int(i*<span class="hljs-number">255</span>)),end=<span class="hljs-string">&quot; &quot;</span>)
    count += <span class="hljs-number">1</span>
    <span class="hljs-keyword">if</span>(count % <span class="hljs-number">28</span> == <span class="hljs-number">0</span>):
        print(end=<span class="hljs-string">&quot;\n&quot;</span>)
</code></pre>
<pre><code>   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0 
   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0 
   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0 
   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0 
   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0 
   0    0    0    0    0    0    0    0    0    0  131   55    0    0    0   43   43   43   69  148   62    0    0    0    0    0    0    0 
   0    0    0    0    0    0    0    0    0    0  148  168    0   22  173  253  252  252  231  124   27    0    0    0    0    0    0    0 
   0    0    0    0    0    0    0    0    0    0  201  246  144  237  252  241  196   73   16    0    0    0    0    0    0    0    0    0 
   0    0    0    0    0    0    0    0    0    0  253  252  252  236  101   35    0    0    0    0    0    0    0    0    0    0    0    0 
   0    0    0    0    0    0    0    0    0   89  253  252  146   31    0    0    0    0    0    0    0    0    0    0    0    0    0    0 
   0    0    0    0    0    0    0    0    0  107  255  183    4    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0 
   0    0    0    0    0    0    0    0    0   27  253  252  135    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0 
   0    0    0    0    0    0    0    0    0    0  144  247  251  206   83    9    0    0    0    0    0    0    0    0    0    0    0    0 
   0    0    0    0    0    0    0    0    0    0    0   99  194  252  252  204   69    0    0    0    0    0    0    0    0    0    0    0 
   0    0    0    0    0    0    0    0    0    0    0    0    4  113  235  253  239   62    0    0    0    0    0    0    0    0    0    0 
   0    0    0    0    0    0    0    0    0    0    0    0    0    0   45  193  253  232    0    0    0    0    0    0    0    0    0    0 
   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0   37  205  247   63    0    0    0    0    0    0    0    0    0 
   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0   94  252  180    0    0    0    0    0    0    0    0    0 
   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0   85  252  189    0    0    0    0    0    0    0    0    0 
   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0  128  252  189    0    0    0    0    0    0    0    0    0 
   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0   43  227  250   70    0    0    0    0    0    0    0    0    0 
   0    0    0    0    0    0    0    0    0    0    0    0    0    0   36  227  252  196    0    0    0    0    0    0    0    0    0    0 
   0    0    0    0    0    0    0    0    0  107   18    8   31  127  223  253  245   72    0    0    0    0    0    0    0    0    0    0 
   0    0    0    0    0    0    0    0    0  185  239  197  252  252  252  199   56    0    0    0    0    0    0    0    0    0    0    0 
   0    0    0    0    0    0    0    0    0   18  209  252  252  182  103   18    0    0    0    0    0    0    0    0    0    0    0    0 
   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0 
   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0 
   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0 
</code></pre><pre><code class="lang-python">label = mnist.test.labels[idx]
print(label)
</code></pre>
<pre><code>[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]
</code></pre><pre><code class="lang-python">plt.title(label)
img = img.reshape(<span class="hljs-number">28</span>,<span class="hljs-number">28</span>)
plt.imshow(img,cmap=plt.get_cmap(<span class="hljs-string">&apos;gray_r&apos;</span>))
</code></pre>
<pre><code>&lt;matplotlib.image.AxesImage at 0x1fdf9240&gt;
</code></pre><p><img src="http://ww2.sinaimg.cn/large/006tNc79ly1g53d1ugei8j307307cdfo.jpg" alt="png"></p>
<h2 id="4&#x6570;&#x636E;&#x9884;&#x5904;&#x7406;">4.&#x6570;&#x636E;&#x9884;&#x5904;&#x7406;</h2>
<pre><code class="lang-python"><span class="hljs-comment">## &#x5206;&#x5272;&#x8BAD;&#x7EC3;&#x96C6;&#x548C;&#x6D4B;&#x8BD5;&#x96C6;</span>
X = mnist.train.images
Y = mnist.train.labels
print(<span class="hljs-string">&quot;&#x8BAD;&#x7EC3;&#x96C6;&#x7279;&#x5F81;&#x7684;&#x5F62;&#x72B6;&#xFF1A;&quot;</span> + str(X.shape))
print(<span class="hljs-string">&quot;&#x8BAD;&#x7EC3;&#x96C6;&#x6807;&#x7B7E;&#x7684;&#x5F62;&#x72B6;&#xFF1A;&quot;</span> + str(Y.shape))

X_test =  mnist.test.images
Y_test =  mnist.test.labels
</code></pre>
<h2 id="3&#x642D;&#x5EFA;&#x6A21;&#x578B;">3.&#x642D;&#x5EFA;&#x6A21;&#x578B;</h2>
<pre><code class="lang-python">model = tf.keras.Sequential()
model.add(tf.keras.layers.Dense(units=<span class="hljs-number">10</span>, input_dim=<span class="hljs-number">784</span>))
<span class="hljs-comment"># &#x6DFB;&#x52A0;&#x6FC0;&#x6D3B;&#x5C42;</span>
model.add(tf.keras.layers.Activation(<span class="hljs-string">&apos;softmax&apos;</span>))
model.summary()  <span class="hljs-comment"># &#x67E5;&#x770B;&#x6A21;&#x578B;&#x7ED3;&#x6784;</span>
</code></pre>
<pre><code>_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_2 (Dense)              (None, 10)                7850      
_________________________________________________________________
activation_2 (Activation)    (None, 10)                0         
=================================================================
Total params: 7,850
Trainable params: 7,850
Non-trainable params: 0
_________________________________________________________________
</code></pre><pre><code class="lang-python">model.compile(loss=<span class="hljs-string">&apos;categorical_crossentropy&apos;</span>, optimizer=<span class="hljs-string">&apos;sgd&apos;</span>,metrics=[<span class="hljs-string">&apos;accuracy&apos;</span>])
</code></pre>
<pre><code class="lang-python">model.fit(X,Y,epochs=<span class="hljs-number">100</span>,batch_size=<span class="hljs-number">100</span>)
</code></pre>
<pre><code>Epoch 1/100
55000/55000 [==============================] - 1s 13us/step - loss: 1.1849 - acc: 0.7279
Epoch 2/100
55000/55000 [==============================] - 1s 10us/step - loss: 0.6705 - acc: 0.8466
Epoch 3/100
55000/55000 [==============================] - 1s 10us/step - loss: 0.5570 - acc: 0.8641
Epoch 4/100
55000/55000 [==============================] - 1s 10us/step - loss: 0.5022 - acc: 0.8723
Epoch 5/100
55000/55000 [==============================] - 1s 10us/step - loss: 0.4686 - acc: 0.8786
Epoch 6/100
55000/55000 [==============================] - 1s 10us/step - loss: 0.4453 - acc: 0.8827
Epoch 7/100
55000/55000 [==============================] - 1s 10us/step - loss: 0.4280 - acc: 0.8861
Epoch 8/100
55000/55000 [==============================] - 1s 10us/step - loss: 0.4145 - acc: 0.8893
Epoch 9/100
55000/55000 [==============================] - 1s 10us/step - loss: 0.4035 - acc: 0.8915
Epoch 10/100
55000/55000 [==============================] - 1s 10us/step - loss: 0.3944 - acc: 0.8931
Epoch 11/100
55000/55000 [==============================] - 1s 10us/step - loss: 0.3866 - acc: 0.8950
Epoch 12/100
55000/55000 [==============================] - 1s 10us/step - loss: 0.3799 - acc: 0.8964
Epoch 13/100
55000/55000 [==============================] - 1s 10us/step - loss: 0.3741 - acc: 0.8974
Epoch 14/100
55000/55000 [==============================] - 1s 10us/step - loss: 0.3688 - acc: 0.8988
Epoch 15/100
55000/55000 [==============================] - 1s 10us/step - loss: 0.3642 - acc: 0.9001
Epoch 16/100
55000/55000 [==============================] - 1s 10us/step - loss: 0.3601 - acc: 0.9008
Epoch 17/100
55000/55000 [==============================] - 1s 10us/step - loss: 0.3562 - acc: 0.9021
Epoch 18/100
55000/55000 [==============================] - 1s 10us/step - loss: 0.3528 - acc: 0.9025
Epoch 19/100
55000/55000 [==============================] - 1s 10us/step - loss: 0.3496 - acc: 0.9033
Epoch 20/100
55000/55000 [==============================] - 1s 10us/step - loss: 0.3466 - acc: 0.9037
Epoch 21/100
55000/55000 [==============================] - 1s 10us/step - loss: 0.3439 - acc: 0.9047
Epoch 22/100
55000/55000 [==============================] - 1s 10us/step - loss: 0.3414 - acc: 0.9050
Epoch 23/100
55000/55000 [==============================] - 1s 10us/step - loss: 0.3390 - acc: 0.9060
Epoch 24/100
55000/55000 [==============================] - 1s 10us/step - loss: 0.3368 - acc: 0.9064
Epoch 25/100
55000/55000 [==============================] - 1s 10us/step - loss: 0.3347 - acc: 0.9069
Epoch 26/100
55000/55000 [==============================] - 1s 10us/step - loss: 0.3328 - acc: 0.9074
Epoch 27/100
55000/55000 [==============================] - 1s 10us/step - loss: 0.3309 - acc: 0.9077
Epoch 28/100
55000/55000 [==============================] - 1s 10us/step - loss: 0.3292 - acc: 0.9083
Epoch 29/100
55000/55000 [==============================] - 1s 10us/step - loss: 0.3275 - acc: 0.9085
Epoch 30/100
55000/55000 [==============================] - 1s 10us/step - loss: 0.3259 - acc: 0.9092
Epoch 31/100
55000/55000 [==============================] - 1s 10us/step - loss: 0.3244 - acc: 0.9095
Epoch 32/100
55000/55000 [==============================] - 1s 10us/step - loss: 0.3230 - acc: 0.9098
Epoch 33/100
55000/55000 [==============================] - 1s 10us/step - loss: 0.3216 - acc: 0.9102
Epoch 34/100
55000/55000 [==============================] - 1s 10us/step - loss: 0.3204 - acc: 0.9106
Epoch 35/100
55000/55000 [==============================] - 1s 10us/step - loss: 0.3191 - acc: 0.9112
Epoch 36/100
55000/55000 [==============================] - 1s 10us/step - loss: 0.3179 - acc: 0.9117
Epoch 37/100
55000/55000 [==============================] - 1s 10us/step - loss: 0.3167 - acc: 0.9119
Epoch 38/100
55000/55000 [==============================] - 1s 10us/step - loss: 0.3157 - acc: 0.9125
Epoch 39/100
55000/55000 [==============================] - 1s 10us/step - loss: 0.3146 - acc: 0.9129
Epoch 40/100
55000/55000 [==============================] - 1s 10us/step - loss: 0.3136 - acc: 0.9132
Epoch 41/100
55000/55000 [==============================] - 1s 10us/step - loss: 0.3126 - acc: 0.9132
Epoch 42/100
55000/55000 [==============================] - 1s 10us/step - loss: 0.3116 - acc: 0.9137
Epoch 43/100
55000/55000 [==============================] - 1s 10us/step - loss: 0.3107 - acc: 0.9139
Epoch 44/100
55000/55000 [==============================] - 1s 10us/step - loss: 0.3098 - acc: 0.9142
Epoch 45/100
55000/55000 [==============================] - 1s 10us/step - loss: 0.3089 - acc: 0.9141
Epoch 46/100
55000/55000 [==============================] - 1s 10us/step - loss: 0.3081 - acc: 0.9148
Epoch 47/100
55000/55000 [==============================] - 1s 14us/step - loss: 0.3073 - acc: 0.9150
Epoch 48/100
55000/55000 [==============================] - 1s 14us/step - loss: 0.3066 - acc: 0.9149
Epoch 49/100
55000/55000 [==============================] - 1s 12us/step - loss: 0.3058 - acc: 0.9151
Epoch 50/100
55000/55000 [==============================] - 1s 11us/step - loss: 0.3051 - acc: 0.9154
Epoch 51/100
55000/55000 [==============================] - 1s 11us/step - loss: 0.3044 - acc: 0.9157
Epoch 52/100
55000/55000 [==============================] - 1s 11us/step - loss: 0.3037 - acc: 0.9155
Epoch 53/100
55000/55000 [==============================] - 1s 10us/step - loss: 0.3030 - acc: 0.9158
Epoch 54/100
55000/55000 [==============================] - 1s 10us/step - loss: 0.3023 - acc: 0.9162
Epoch 55/100
55000/55000 [==============================] - 1s 10us/step - loss: 0.3017 - acc: 0.9161
Epoch 56/100
55000/55000 [==============================] - 1s 10us/step - loss: 0.3011 - acc: 0.9167
Epoch 57/100
55000/55000 [==============================] - 1s 10us/step - loss: 0.3004 - acc: 0.9166
Epoch 58/100
55000/55000 [==============================] - 1s 10us/step - loss: 0.2999 - acc: 0.9166
Epoch 59/100
55000/55000 [==============================] - 1s 10us/step - loss: 0.2993 - acc: 0.9170
Epoch 60/100
55000/55000 [==============================] - 1s 10us/step - loss: 0.2987 - acc: 0.9173
Epoch 61/100
55000/55000 [==============================] - 1s 10us/step - loss: 0.2981 - acc: 0.9170
Epoch 62/100
55000/55000 [==============================] - 1s 10us/step - loss: 0.2977 - acc: 0.9174
Epoch 63/100
55000/55000 [==============================] - 1s 10us/step - loss: 0.2971 - acc: 0.9174
Epoch 64/100
55000/55000 [==============================] - 1s 10us/step - loss: 0.2966 - acc: 0.9177
Epoch 65/100
55000/55000 [==============================] - 1s 10us/step - loss: 0.2961 - acc: 0.9174
Epoch 66/100
55000/55000 [==============================] - 1s 10us/step - loss: 0.2956 - acc: 0.9177
Epoch 67/100
55000/55000 [==============================] - 1s 10us/step - loss: 0.2952 - acc: 0.9180
Epoch 68/100
55000/55000 [==============================] - 1s 10us/step - loss: 0.2947 - acc: 0.9179
Epoch 69/100
55000/55000 [==============================] - 1s 10us/step - loss: 0.2942 - acc: 0.9183
Epoch 70/100
55000/55000 [==============================] - 1s 10us/step - loss: 0.2938 - acc: 0.9180
Epoch 71/100
55000/55000 [==============================] - 1s 10us/step - loss: 0.2933 - acc: 0.9184
Epoch 72/100
55000/55000 [==============================] - 1s 10us/step - loss: 0.2929 - acc: 0.9183
Epoch 73/100
55000/55000 [==============================] - 1s 10us/step - loss: 0.2924 - acc: 0.9186
Epoch 74/100
55000/55000 [==============================] - 1s 10us/step - loss: 0.2921 - acc: 0.9185
Epoch 75/100
55000/55000 [==============================] - 1s 10us/step - loss: 0.2917 - acc: 0.9188
Epoch 76/100
55000/55000 [==============================] - 1s 10us/step - loss: 0.2913 - acc: 0.9187
Epoch 77/100
55000/55000 [==============================] - 1s 10us/step - loss: 0.2909 - acc: 0.9191
Epoch 78/100
55000/55000 [==============================] - 1s 10us/step - loss: 0.2905 - acc: 0.9193
Epoch 79/100
55000/55000 [==============================] - 1s 10us/step - loss: 0.2901 - acc: 0.9193
Epoch 80/100
55000/55000 [==============================] - 1s 10us/step - loss: 0.2897 - acc: 0.9193
Epoch 81/100
55000/55000 [==============================] - 1s 10us/step - loss: 0.2894 - acc: 0.9191
Epoch 82/100
55000/55000 [==============================] - 1s 10us/step - loss: 0.2890 - acc: 0.9193
Epoch 83/100
55000/55000 [==============================] - 1s 10us/step - loss: 0.2887 - acc: 0.9193
Epoch 84/100
55000/55000 [==============================] - 1s 10us/step - loss: 0.2884 - acc: 0.9194
Epoch 85/100
55000/55000 [==============================] - 1s 10us/step - loss: 0.2879 - acc: 0.9196
Epoch 86/100
55000/55000 [==============================] - 1s 10us/step - loss: 0.2877 - acc: 0.9199
Epoch 87/100
55000/55000 [==============================] - 1s 10us/step - loss: 0.2873 - acc: 0.9200
Epoch 88/100
55000/55000 [==============================] - 1s 10us/step - loss: 0.2870 - acc: 0.9199
Epoch 89/100
55000/55000 [==============================] - 1s 10us/step - loss: 0.2867 - acc: 0.9201
Epoch 90/100
55000/55000 [==============================] - 1s 10us/step - loss: 0.2864 - acc: 0.9201
Epoch 91/100
55000/55000 [==============================] - 1s 10us/step - loss: 0.2861 - acc: 0.9201
Epoch 92/100
55000/55000 [==============================] - 1s 10us/step - loss: 0.2858 - acc: 0.9202
Epoch 93/100
55000/55000 [==============================] - 1s 10us/step - loss: 0.2855 - acc: 0.9204
Epoch 94/100
55000/55000 [==============================] - 1s 10us/step - loss: 0.2852 - acc: 0.9206
Epoch 95/100
55000/55000 [==============================] - 1s 10us/step - loss: 0.2849 - acc: 0.9207
Epoch 96/100
55000/55000 [==============================] - 1s 10us/step - loss: 0.2846 - acc: 0.9205
Epoch 97/100
55000/55000 [==============================] - 1s 10us/step - loss: 0.2843 - acc: 0.9207
Epoch 98/100
55000/55000 [==============================] - 1s 10us/step - loss: 0.2841 - acc: 0.9208
Epoch 99/100
55000/55000 [==============================] - 1s 10us/step - loss: 0.2838 - acc: 0.9209
Epoch 100/100
55000/55000 [==============================] - 1s 10us/step - loss: 0.2835 - acc: 0.9209





&lt;tensorflow.python.keras.callbacks.History at 0x11962c50&gt;
</code></pre><h2 id="4&#x8BC4;&#x4F30;&#x6A21;&#x578B;">4.&#x8BC4;&#x4F30;&#x6A21;&#x578B;</h2>
<pre><code class="lang-python">loss,acc = model.evaluate(X_test,Y_test)
print(acc)
</code></pre>
<pre><code>10000/10000 [==============================] - 0s 17us/step
0.9209
</code></pre><h2 id="5&#x6A21;&#x578B;&#x7684;&#x4F7F;&#x7528;">5.&#x6A21;&#x578B;&#x7684;&#x4F7F;&#x7528;</h2>
<pre><code class="lang-python">idx = np.random.randint(<span class="hljs-number">10000</span>)
img = mnist.test.images[idx]
img = img.reshape(<span class="hljs-number">28</span>,<span class="hljs-number">28</span>)
plt.imshow(img,cmap=plt.get_cmap(<span class="hljs-string">&apos;gray_r&apos;</span>))
</code></pre>
<pre><code>&lt;matplotlib.image.AxesImage at 0x23c3cdd8&gt;
</code></pre><p><img src="output_20_1.png" alt="png"></p>
<pre><code class="lang-python">img = img.reshape(<span class="hljs-number">1</span>,<span class="hljs-number">784</span>)
print(<span class="hljs-string">&quot;=====&#x9884;&#x6D4B;&#x503C;=====&quot;</span>)
print(model.predict(img).argmax())
label = mnist.test.labels[idx]
print(<span class="hljs-string">&quot;=====&#x771F;&#x5B9E;&#x503C;=====&quot;</span>)
print(label.argmax())
</code></pre>
<pre><code>=====&#x9884;&#x6D4B;&#x503C;=====
2
=====&#x771F;&#x5B9E;&#x503C;=====
2
</code></pre><h2 id="6&#x6A21;&#x578B;&#x7684;&#x4FDD;&#x5B58;">6.&#x6A21;&#x578B;&#x7684;&#x4FDD;&#x5B58;</h2>
<pre><code class="lang-python">model.save(<span class="hljs-string">&quot;model_mnist_linear.h5&quot;</span>)
<span class="hljs-keyword">del</span> model
</code></pre>

                                
                                </section>
                            
    </div>
    <div class="search-results">
        <div class="has-results">
            
            <h1 class="search-results-title"><span class='search-results-count'></span> results matching "<span class='search-query'></span>"</h1>
            <ul class="search-results-list"></ul>
            
        </div>
        <div class="no-results">
            
            <h1 class="search-results-title">No results matching "<span class='search-query'></span>"</h1>
            
        </div>
    </div>
</div>

                        </div>
                    </div>
                
            </div>

            
                
                <a href="../11_appendix_summary.html" class="navigation navigation-prev " aria-label="Previous page: 附录">
                    <i class="fa fa-angle-left"></i>
                </a>
                
                
                <a href="code02_mnist_cnn.html" class="navigation navigation-next " aria-label="Next page: 卷积神经网络代码清单">
                    <i class="fa fa-angle-right"></i>
                </a>
                
            
        
    </div>

    <script>
        var gitbook = gitbook || [];
        gitbook.push(function() {
            gitbook.page.hasChanged({"page":{"title":"softmax回归代码清单","level":"1.11.1","depth":2,"next":{"title":"卷积神经网络代码清单","level":"1.11.2","depth":2,"path":"code/code02_mnist_cnn.md","ref":"code/code02_mnist_cnn.md","articles":[]},"previous":{"title":"附录","level":"1.11","depth":1,"path":"11_appendix_summary.md","ref":"11_appendix_summary.md","articles":[{"title":"softmax回归代码清单","level":"1.11.1","depth":2,"path":"code/code01_mnist_linear_softmax.md","ref":"code/code01_mnist_linear_softmax.md","articles":[]},{"title":"卷积神经网络代码清单","level":"1.11.2","depth":2,"path":"code/code02_mnist_cnn.md","ref":"code/code02_mnist_cnn.md","articles":[]}]},"dir":"ltr"},"config":{"gitbook":"*","theme":"default","variables":{},"plugins":[],"pluginsConfig":{"highlight":{},"search":{},"lunr":{"maxIndexSize":1000000,"ignoreSpecialCharacters":false},"sharing":{"facebook":true,"twitter":true,"google":false,"weibo":false,"instapaper":false,"vk":false,"all":["facebook","google","twitter","weibo","instapaper"]},"fontsettings":{"theme":"white","family":"sans","size":2},"theme-default":{"styles":{"website":"styles/website.css","pdf":"styles/pdf.css","epub":"styles/epub.css","mobi":"styles/mobi.css","ebook":"styles/ebook.css","print":"styles/print.css"},"showLevel":false}},"structure":{"langs":"LANGS.md","readme":"README.md","glossary":"GLOSSARY.md","summary":"SUMMARY.md"},"pdf":{"pageNumbers":true,"fontSize":12,"fontFamily":"Arial","paperSize":"a4","chapterMark":"pagebreak","pageBreaksBefore":"/","margin":{"right":62,"left":62,"top":56,"bottom":56}},"styles":{"website":"styles/website.css","pdf":"styles/pdf.css","epub":"styles/epub.css","mobi":"styles/mobi.css","ebook":"styles/ebook.css","print":"styles/print.css"}},"file":{"path":"code/code01_mnist_linear_softmax.md","mtime":"2019-07-17T17:44:26.000Z","type":"markdown"},"gitbook":{"version":"3.2.3","time":"2019-07-18T00:14:40.121Z"},"basePath":"..","book":{"language":""}});
        });
    </script>
</div>

        
    <script src="../gitbook/gitbook.js"></script>
    <script src="../gitbook/theme.js"></script>
    
        
        <script src="../gitbook/gitbook-plugin-search/search-engine.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-search/search.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-lunr/lunr.min.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-lunr/search-lunr.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-sharing/buttons.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-fontsettings/fontsettings.js"></script>
        
    

    </body>
</html>

